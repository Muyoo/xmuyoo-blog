<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>逻辑回归的笔记 - 潇慕雨Muyoo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="之前使用逻辑回归时就接触到里面的sigmod函数，就有疑问为什么会想到用这个函数把线性回归的值压缩到0到1之间；而看到的介绍逻辑回归的公开课、文章，大多数都对此没有详细说明。所以现在又把LR拿出来，记录下从别人文章里学到的解释，同时也理一理逻辑回归的过程和现在的一些理解。
有错误、不当之处欢迎指出！
线性回归在这之前，需要先提一下线性回归。
线性回归比较简单，从二维的空间比较容易从直观上理解：给定">
<meta property="og:type" content="article">
<meta property="og:title" content="逻辑回归的笔记">
<meta property="og:url" content="http://www.xmuyoo.com/2016/12/07/LogisticRegressionNote/index.html">
<meta property="og:site_name" content="潇慕雨Muyoo">
<meta property="og:description" content="之前使用逻辑回归时就接触到里面的sigmod函数，就有疑问为什么会想到用这个函数把线性回归的值压缩到0到1之间；而看到的介绍逻辑回归的公开课、文章，大多数都对此没有详细说明。所以现在又把LR拿出来，记录下从别人文章里学到的解释，同时也理一理逻辑回归的过程和现在的一些理解。
有错误、不当之处欢迎指出！
线性回归在这之前，需要先提一下线性回归。
线性回归比较简单，从二维的空间比较容易从直观上理解：给定">
<meta property="og:image" content="http://7vzs9m.com1.z0.glb.clouddn.com/%E5%A4%A7%E7%90%8677.jpg">
<meta property="og:updated_time" content="2016-12-07T01:00:00.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="逻辑回归的笔记">
<meta name="twitter:description" content="之前使用逻辑回归时就接触到里面的sigmod函数，就有疑问为什么会想到用这个函数把线性回归的值压缩到0到1之间；而看到的介绍逻辑回归的公开课、文章，大多数都对此没有详细说明。所以现在又把LR拿出来，记录下从别人文章里学到的解释，同时也理一理逻辑回归的过程和现在的一些理解。
有错误、不当之处欢迎指出！
线性回归在这之前，需要先提一下线性回归。
线性回归比较简单，从二维的空间比较容易从直观上理解：给定">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link href="/webfonts/ptserif/main.css" rel='stylesheet' type='text/css'>
  <link href="/webfonts/source-code-pro/main.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css" type="text/css">
  
<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', '[object Object]', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics -->


</head>

<body>
  <div id="container">
    <header id="header">
  <div id="header-outer" class="outer">
    <div id="header-inner" class="inner">
      <a id="main-nav-toggle" class="nav-icon" href="javascript:;"></a>
      <a id="logo" class="logo" href="/"></a>
      <nav id="main-nav">
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/about/index.html">About</a>
        
      </nav>
      <nav id="sub-nav">
        <div id="search-form-wrap">
          <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://www.xmuyoo.com"></form>
        </div>
      </nav>
    </div>
  </div>
</header>
    <section id="main" class="outer"><article id="post-LogisticRegressionNote" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      逻辑回归的笔记
    </h1>
  

      </header>
    
    <div class="article-meta">
      <a href="/2016/12/07/LogisticRegressionNote/" class="article-date">
  <time datetime="2016-12-07T01:00:00.000Z" itemprop="datePublished">2016-12-07</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/技术/">技术</a><span>></span><a class="article-category-link" href="/categories/技术/逻辑回归/">逻辑回归</a>
  </div>

      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <p><img src="http://7vzs9m.com1.z0.glb.clouddn.com/%E5%A4%A7%E7%90%8677.jpg" alt="这里少通汽车，每天只有几班车通往外界，却是自我归零的佳地。—— By Muyoo"></p>
<p>之前使用逻辑回归时就接触到里面的sigmod函数，就有疑问为什么会想到用这个函数把线性回归的值压缩到0到1之间；而看到的介绍逻辑回归的公开课、文章，大多数都对此没有详细说明。所以现在又把LR拿出来，记录下从别人文章里学到的解释，同时也理一理逻辑回归的过程和现在的一些理解。</p>
<p>有错误、不当之处欢迎指出！</p>
<h3 id="线性回归">线性回归</h3><p>在这之前，需要先提一下线性回归。</p>
<p>线性回归比较简单，从二维的空间比较容易从直观上理解：给定了一组点，然后找到一条线能够拟合这些点。这里所说的“点”就是我们拿到的样本，“线”就是我们要找到的模型（或者说函数）。</p>
<p>线性回归写出来的样子就是：</p>
<p>$$h(x) = x_0\theta_0+x_1\theta_1+x_2\theta_2+\ldots+x_n\theta_n$$</p>
<a id="more"></a>
<p>用向量的方式表达就是：</p>
<p>$$ h(x) = \theta^TX $$</p>
<p>$\theta$是我们的参数，$X$是我们的样本。从上面的公式我们能够看到，线性回归的结果的取值范围是实数范围。</p>
<p>它用来预测某事件的数值是没问题的，那么它可不可以用来做分类的判断呢，也就是能不能用于回答“是”或“否”的问题呢？</p>
<p>从概率的角度看，我们如果能够想办法将这个线性回归的值转变成一个概率值，也就是把它弄到$[0,1]$这个范围内，不是就可以了吗？就变成了通过回答“是的概率有多大”来间接回答“是”或“否”的问题。</p>
<h3 id="利用线性回归的值来回答“是”或“否”">利用线性回归的值来回答“是”或“否”</h3><p>在这，我们先抛开“怎么把线性回归的值弄到$[0,1]$之间”这个问题。我们先来看一下我们关心的“是否”问题本身。</p>
<p>还是从概率的角度，我们可以将“是的概率”看作“事件发生的概率”，“回答否的概率”看作“事件不发生的概率”。那么，就可以将“事件发生的概率”设为$P$，而“事件不发生的概率”设为$1-P$。</p>
<p>实际上，我到现在还有一点不太明白大神们是如何想到要做下面这个操作的（我能想到的就是看起来$P$和$1-P$都是操作同一个数值、而$P$又在$[0,1]$之间，所以直觉上会利用它们的比值）：</p>
<p>$$ \frac{P}{1-P} $$</p>
<p>当$P \to 0$时，这个的结果是$\to 0$；当$P \to 1$时，这个的结果是$\to \infty$。所以现在我们再看刚才提到的线性回归的结果范围，我们已经有了一半了：$[0,\infty]$。</p>
<p>那么剩下的一半呢？我理解，这又是大神们的直觉了，利用了$ln$函数，得到：</p>
<p>$$\ln(\frac{P}{1-P})$$</p>
<p>因为$\frac{P}{1-P}$是在$[0,\infty]$的，所以正好是$log$函数标准的定义域，然后就得到了其标准的值域：$[-\infty,\infty]$，也就刚好是我们线性回归的结果范围了。于是，我们就可以得到：</p>
<p>$$\ln(\frac{P}{1-P})=\theta^TX $$<br>$$\implies \frac{P}{1-P} = e^{\theta^TX}$$<br>$$\implies P = (1-P)e^{\theta^TX}$$<br>$$\implies P = \frac{1}{1+e^{-\theta^TX}} $$</p>
<p>然后我们令$z(X) = -\theta^TX$，就得到了：<br>$$P = \frac{1}{1+e^z}$$</p>
<p>这个就是我们常见的sigmod函数了。</p>
<p>现在我们能够利用线性回归的值来回答“事件发生的概率”这个问题了。</p>
<p>那么剩下的问题就是我们如何找到$\theta$这个参数呢？</p>
<h3 id="找寻我们的参数$\theta$">找寻我们的参数$\theta$</h3><p>现在，我们有了计算“事件发生概率”的计算式，我们也有了一些样本数据。观察这个计算式，我们就差那个$\theta$了。</p>
<p>那么，“那个$\theta$是什么”其实直观上一下子能想到这个问题的意思也就是“我们有了一组样本，要怎么计算出那个$\theta$呢？”。这里，我们需要提一下极大似然（MLE）。 </p>
<blockquote>
<p>极大似然<br>刚才的问题可以反过来想成是：“什么$\theta$值能够让我最有可能得到现在这些样本？”。用正式些的说法就是，“找到$\theta$使出现现有样本可能性最大”。这就是极大似然估计（MLE）的主要思想。<br>用概率中的条件概率表达式写出来就是：<br>$$P(x^{(1)},x^{(2)},x^{(3)},\ldots,x^{(n)}|\theta)$$<br>我们这里有一个假设：我们的样本是独立同分布的（也就是说任何两个样本之间的出现没有联系、各自独立出现），并且这些样本能够代表总体样本。<br>那么上面这个等式就可以写成：<br>$$P(x^{(1)}|\theta)P(x^{(2)}|\theta)P(x^{(3)}|\theta) \ldots P(x^{(n)}|\theta)$$<br>$$\implies \prod_{i=1}^n P(x^{(i)}|\theta)$$<br>其实是所有样本联合概率分布。</p>
</blockquote>
<p>在这里，对于样本$x^{(i)}$，它的概率预测值我们可以写成 $P(x^{(i)})$，我们先不将$\theta$写出来。由于我们的分类问题是二分类，也就是结果等于1或者0。那么表示出来就是$y^{(i)} = 1$ 或 $y^{(i)} = 0$。那么这个概率预测值可以写成：<br>对于样本$x^{(i)}$，有：<br>$$P(y^{(i)} = 1|x^{(i)})^{y^{(i)}}\ast P(y^{(i)} = 0|x^{(i)})^{1-y^{(i)}}$$<br>当$y^{(i)} = 1$时，上式等于$P(y^{(i)} = 1|x^{(i)})$；当 $y^{(i)} = 0$时，上式等于$P(y^{(i)} = 0|x^{(i)})$（我们的$\theta$是在这个$P()$中的，逻辑回归的公式：$P(X)=\frac{1}{1+e^{-\theta^{T}X}}$）。</p>
<p>结合极大似然的思想，我们就可以得到：<br>$$\prod_{i=1}^nP(y^{(i)}=1|x^{(i)})^{y^{(i)}}\ast P(y^{(i)}=0|x^{(i)})^{1-y^{(i)}}$$</p>
<p>现在，“极大”就是要求“最大”、求“Max”，也就是求上式的“Max”。这时，我们又可以对其用对数函数来做一步转换。</p>
<blockquote>
<p>这里用对数函数做转换的主要原因是，要想求“Max”或是“Min”，得是凸函数（convex）或是凹函数才行。然而上面的式子是非凸的（non-convex），也是非凹的。通过用对数函数转换后的结果是convex的。</p>
</blockquote>
<p>转换后的结果是：<br>$$\log(\prod<em>{i=1}^nP(y^{(i)}=1|x^{(i)})^{y^{(i)}}\ast P(y^{(i)}=0|x^{(i)})^{1-y^{(i)}})$$<br>也就是对这个式子求“Max”。但它是convex的，求“min”要更好一点。就将这个“求Max”的问题转换为求它的对偶问题求“Min”：$min(-\log())$，而$-\log()$通过对数函数的性质就可以得到：<br>$$J(\theta) = \frac{1}{n}\ast \sum</em>{i=1}^n\underbrace{y^{(i)}\log(h(x^{(i)}))+(1-y^{(i)})\log(1-h(x^{(i)}))}_{h(x^{(i)})=\frac{1}{1+e^{-\theta^{T}X^{(i)}}}}$$</p>
<p>到这里，可以看到这就是逻辑回归的Cost Function了（在这里还没考虑正则化项）。通过对这个式子求解“Min”，得到“min”时的参数就是我们要找寻的参数了。</p>
<p>那么从刚才的过程中可以得知，找到那个“Min”值的时候，我们得到的参数就是我们想要的$\theta$。那我们如何找到这个“Min”值？</p>
<p>在这里，这个问题不深入记录。在新的一篇文章里专门来记录几种找到这个“Min”值，这样安排或许更好一点。这里只提一下常用、常听到的一些：</p>
<ul>
<li>批量梯度下降</li>
<li>随机梯度下降</li>
<li>拟牛顿法</li>
</ul>
<p>另外还有一个很重要的：正则化。</p>
<h3 id="对逻辑回归的一点感受">对逻辑回归的一点感受</h3><p>通过把这整个过程理一遍后，对于逻辑回归的一些特点也有了一些理解。这些之前只是听别人、看文章这么说，但其实理解不够。这下感觉自己对这些特点的理解又深了一些。</p>
<ul>
<li>在样本数较多时比较好。因为它通过极大似然来推导出cost function，而极大似然的思想中有“现有样本可以代表总体样本”这一点。那么，总体样本当然是很多的，要想代表总体，那自然而然现有样本数是越多越能代表总体了。而且，极大似然是点估计的方法，对参数、模型没有先验在里面，所以样本数越多，知道的信息就越多，就越知道总体样本的“长相”是什么样子。</li>
<li>用于训练的特征之间最好相互联系较少，也就是参数之间尽量独立。这一点自己感觉有一点取决于用什么方法去找“Min”。比如梯度下降中，是对每个参数$\theta_j$求偏导。那么在对某个$\theta$求偏导时，其它参数是无差别全部参与进来。个人理解这就相当于切断了与其它参数的联系。如果这个$\theta$跟其它参数是紧密联系的，这么一切，联系断掉，就有点呵呵了；那如果是没有联系的，就正好符合这过程。</li>
<li>好解释。因为它的公式中$Z(X)=\theta^TX$本身是一个线性回归。线性回归的思路就容易弄清楚，然后它哪个参数、哪个特征起的作用大也很容易弄清楚。当然，这也需要在指定特征的时候，尽可能使特征、特征值的含义明确。 </li>
<li>容易并行化。这跟两个地方有关系，一是逻辑回归预测公式本身，另一个是求“Min”的方法。它本身的公式中$\theta^TX$，是一个向量，可以并行计算的；另外，还是假设用的梯度下降，梯度下降中求解每个$\theta_j$偏导的时候，也是可以并行计算的。</li>
</ul>
<h3 id="参考">参考</h3><ul>
<li><a href="http://www.hanlongfei.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2015/08/05/mle" target="_blank" rel="external">机器学习－逻辑回归与最大似然估计</a></li>
<li><a href="https://www.cnblogs.com/liliu/archive/2010/11/24/1886110.html" target="_blank" rel="external">极大似然估计</a></li>
</ul>

      
    </div>
    
    
      <footer class="article-footer">
        
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Linear-Regression/">Linear Regression</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Logistic-Regression/">Logistic Regression</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/MLE/">MLE</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/极大似然估计/">极大似然估计</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/逻辑回归/">逻辑回归</a></li></ul>

      </footer>
    
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2016/12/04/SomethingAboutThreadSafeInJava/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">Java中Synchronized、Volatile、Atomic的一些事&nbsp;<span>&gt;</span></div>
    </a>
  
</nav>

  
</article>

</section>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2016 Muyoo&nbsp;
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, theme by <a href="http://github.com/ppoffice">PPOffice</a>
    </div>
  </div>
</footer>
    

<script src="/js/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">
  <script src="/fancybox/jquery.fancybox.pack.js" type="text/javascript"></script>


<script src="/js/script.js" type="text/javascript"></script>
  </div>
</body>
</html>